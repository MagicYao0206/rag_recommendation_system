# 1. ä¾èµ–å¯¼å…¥å±‚
import pandas as pd

import sys
import os
# æ‰“å°Pythonæœç´¢è·¯å¾„
print("Pythonæœç´¢è·¯å¾„ï¼š", sys.path)

# å°è¯•å®šä½faisså®‰è£…ä½ç½®
try:
    import faiss
    print("faisså®‰è£…è·¯å¾„ï¼š", faiss.__file__)
except ImportError:
    # æ‰‹åŠ¨æ£€æŸ¥å½“å‰ç¯å¢ƒçš„site-packagesä¸­æ˜¯å¦æœ‰faiss
    site_packages = [p for p in sys.path if 'site-packages' in p]
    print("ç¯å¢ƒsite-packagesè·¯å¾„ï¼š", site_packages)
    for sp in site_packages:
        faiss_path = os.path.join(sp, 'faiss')
        print(f"æ£€æŸ¥è·¯å¾„ {faiss_path} æ˜¯å¦å­˜åœ¨ï¼š", os.path.exists(faiss_path))

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from deep_translator import GoogleTranslator

# 2. èµ„æºåŠ è½½å±‚ï¼šåŠ è½½é¢„æ„å»ºçš„å‘é‡åº“ã€æ˜ å°„è¡¨ã€åµŒå…¥æ¨¡å‹ï¼ˆä¸æ„å»ºå±‚ä¸€è‡´ï¼‰
index = faiss.read_index(r"F:\rag_recommendation_system\vector_db\amazon_beauty_index.faiss")
chunks_df = pd.read_csv(r"F:\rag_recommendation_system\vector_db\chunks_mapping.csv", encoding="utf-8-sig")
model = SentenceTransformer("all-MiniLM-L6-v2")

# 3. æ ¸å¿ƒå‡½æ•°å±‚ï¼šå°è£…æ£€ç´¢é€»è¾‘ï¼ˆå¯¹å¤–æä¾›ç»Ÿä¸€æ¥å£ï¼‰
def translate_to_english(text):
    """å°†ä¸­æ–‡æŸ¥è¯¢ç¿»è¯‘æˆè‹±æ–‡"""
    try:
        # æ£€æµ‹æ˜¯å¦ä¸ºä¸­æ–‡ï¼Œè‹¥æ˜¯åˆ™ç¿»è¯‘
        if any('\u4e00' <= char <= '\u9fff' for char in text):
            translated = GoogleTranslator(source='zh-CN', target='en').translate(text)
            print(f"ğŸ“Œ ä¸­æ–‡æŸ¥è¯¢å·²ç¿»è¯‘ï¼š{text} â†’ {translated}")
            return translated
        return text  # éä¸­æ–‡ç›´æ¥è¿”å›
    except Exception as e:
        print(f"âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æœ¬æ£€ç´¢ï¼š{e}")
        return text
    
def retrieve_products(query, top_k=5):
    """
    è¾“å…¥ç”¨æˆ·æé—®ï¼Œè¿”å›Top-Kç›¸å…³å•†å“
    :param query: ç”¨æˆ·æé—®ï¼ˆè‹±æ–‡ï¼‰
    :param top_k: æœ€ç»ˆå¬å›å•†å“æ•°
    :return: å»é‡åçš„å•†å“DataFrame
    """
    query_english = translate_to_english(query)
    # æ­¥éª¤1ï¼šç”Ÿæˆæé—®çš„å‘é‡ï¼ˆä¸ç‰‡æ®µå‘é‡åŒæ¨¡å‹/åŒå½’ä¸€åŒ–ï¼‰
    query_embedding = model.encode([query_english], normalize_embeddings=True).astype("float32")
    
    # æ­¥éª¤2ï¼šFAISSæ£€ç´¢ï¼ˆå¤šå¬å›3å€ï¼Œç”¨äºå»é‡ï¼‰
    scores, indices = index.search(query_embedding, top_k * 3)  # å¦‚top_k=5ï¼Œå…ˆå¬å›15ä¸ªç‰‡æ®µ
    
    # æ­¥éª¤3ï¼šæ˜ å°„åˆ°æ–‡æœ¬ç‰‡æ®µï¼Œæ·»åŠ ç›¸ä¼¼åº¦å¾—åˆ†
    retrieved_chunks = chunks_df.iloc[indices[0]]  # æŒ‰æ£€ç´¢ç´¢å¼•å–ç‰‡æ®µ
    retrieved_chunks = retrieved_chunks.copy()  # å…ˆåˆ›å»ºå‰¯æœ¬
    retrieved_chunks["similarity_score"] = scores[0]
    
    # æ­¥éª¤4ï¼šæŒ‰å•†å“IDå»é‡ï¼ˆä¸€ä¸ªå•†å“å¯èƒ½å¯¹åº”å¤šä¸ªç‰‡æ®µï¼Œä¿ç•™å¾—åˆ†æœ€é«˜çš„ï¼‰
    retrieved_products = retrieved_chunks.sort_values("similarity_score", ascending=False)
    retrieved_products = retrieved_products.drop_duplicates(subset="parent_asin", keep="first")
    
    # æ­¥éª¤5ï¼šè¿”å›Top-Kæ ¸å¿ƒä¿¡æ¯
    result = retrieved_products[["parent_asin", "title", "price", "main_category", "similarity_score"]].head(top_k)
    return result

# 4. æµ‹è¯•å±‚ï¼šéªŒè¯å‡½æ•°åŠŸèƒ½ï¼ˆç‹¬ç«‹è¿è¡Œæ—¶æ‰§è¡Œï¼‰
if __name__ == "__main__":
    query = "oil control facial cleanser for acne-prone skin"
    results = retrieve_products(query, top_k=3)
    print("ğŸ” æ£€ç´¢ç»“æœï¼š")
    print(results)