# 1. ä¾èµ–å¯¼å…¥å±‚ï¼šæ•°æ®å¤„ç†+å‘é‡åº“+æ•°å€¼è®¡ç®—+åµŒå…¥æ¨¡å‹
import pandas as pd
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# 2. æ•°æ®åŠ è½½å±‚ï¼šè¯»å–åˆ‡åˆ†åçš„æ–‡æœ¬ç‰‡æ®µ
chunks_df = pd.read_csv(r"F:\rag_recommendation_system\data\amazon_beauty_chunks.csv", encoding="utf-8-sig")

# 3. æ¨¡å‹åŠ è½½å±‚ï¼šé€‰æ‹©è½»é‡è‹±æ–‡åµŒå…¥æ¨¡å‹ï¼ˆall-MiniLM-L6-v2ï¼š384ç»´ï¼Œé€Ÿåº¦å¿«ï¼‰
model = SentenceTransformer("all-MiniLM-L6-v2")

# 4. å‘é‡ç”Ÿæˆå±‚ï¼šæ‰¹é‡ç¼–ç æ–‡æœ¬ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ•°æ®å¯¼è‡´å†…å­˜æº¢å‡ºï¼‰
batch_size = 1000  # æ‰¹é‡å¤§å°ï¼ˆæ ¹æ®å†…å­˜è°ƒæ•´ï¼Œ8Gå†…å­˜å»ºè®®500ï¼‰
embeddings = []
for i in range(0, len(chunks_df), batch_size):
    batch_texts = chunks_df["chunk_text"].iloc[i:i+batch_size].tolist()
    batch_embeddings = model.encode(batch_texts, normalize_embeddings=True)  # å½’ä¸€åŒ–ï¼ˆé€‚é…ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    embeddings.extend(batch_embeddings)
embeddings = np.array(embeddings).astype("float32")  # FAISSè¦æ±‚float32ç±»å‹

# 5. å‘é‡åº“æ„å»ºå±‚ï¼šåˆå§‹åŒ–FAISSç´¢å¼•å¹¶æ·»åŠ å‘é‡
dimension = embeddings.shape[1]  # è·å–å‘é‡ç»´åº¦ï¼ˆ384ï¼‰
index = faiss.IndexFlatIP(dimension)  # IndexFlatIPï¼šå†…ç§¯æ£€ç´¢ï¼ˆå½’ä¸€åŒ–å=ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
index.add(embeddings)  # å°†æ‰€æœ‰å‘é‡åŠ å…¥ç´¢å¼•

# 6. ç»“æœä¿å­˜å±‚ï¼šä¿å­˜å‘é‡åº“+æ˜ å°„è¡¨ï¼ˆç¼ºä¸€ä¸å¯ï¼ï¼‰
faiss.write_index(index, r"F:\rag_recommendation_system\vector_db\amazon_beauty_index.faiss")
chunks_df.to_csv(r"F:\rag_recommendation_system\vector_db\chunks_mapping.csv", index=False, encoding="utf-8-sig")

# 7. æ—¥å¿—è¾“å‡ºå±‚ï¼šéªŒè¯æ„å»ºç»“æœ
print(f"âœ… å‘é‡åº“æ„å»ºå®Œæˆï¼")
print(f"ğŸ“Š å‘é‡ç»´åº¦ï¼š{dimension}ï¼Œç‰‡æ®µæ•°ï¼š{len(chunks_df)}")